// Copyright (c) Sleipnir contributors

#pragma once

#include <Eigen/Core>
#include <Eigen/SparseCore>

#include "optimization/solver/util/LagrangeMultiplierRescaler.hpp"
#include "optimization/solver/util/ModifiedLagrangian.hpp"

// See docs/algorithms.md#Works_cited for citation definitions

namespace sleipnir {
/**
 * Checks that the KKT conditions are satisfied to some accuracy.
 *
 * @param TODO
 */
inline bool IsLocallyOptimal(const Eigen::VectorXd& y, const Eigen::VectorXd& s,
                             const Eigen::VectorXd& c_i,
                             const Eigen::VectorXd& lagrangian,
                             const double ε_opt) {
  auto σ = LagrangeMultiplierRescaler;
  return σ(y) * lagrangian.lpNorm<Eigen::Infinity>() <= ε_opt ||
         σ(y) * (s.cwiseProduct(y)).lpNorm<Eigen::Infinity>() <= ε_opt ||
         (c_i + s).lpNorm<Eigen::Infinity>() <= ε_opt;
}

/**
 * Checks that the KKT conditions are satisfied to some accuracy.
 *
 * @param TODO
 */
inline bool IsLocallyOptimal(
    const Eigen::VectorXd& y, const Eigen::VectorXd& s,
    const Eigen::VectorXd& c_i, const Eigen::SparseVector<double>& g,
    const Eigen::SparseVector<double>& complimentarityGradient,
    const Eigen::SparseVector<double>& constraintSumGradient, const double β_1,
    const double ε_opt) {
  return IsLocallyOptimal(
      y, s, c_i,
      ManualGradientModifiedLagrangian(g, complimentarityGradient,
                                       constraintSumGradient, 0, β_1),
      ε_opt);
}

/**
 * Checks that the KKT conditions are satisfied to some accuracy.
 *
 * @param TODO
 */
inline bool IsLocallyOptimal(const Eigen::VectorXd& y, const Eigen::VectorXd& s,
                             const Eigen::VectorXd& c_i,
                             const Eigen::SparseVector<double>& g,
                             const Eigen::SparseVector<double>& A_i,
                             const double β_1, const double ε_opt) {
  return IsLocallyOptimal(
      y, s, c_i, ManualGradientModifiedLagrangian(g, A_i, y, 0, β_1), ε_opt);
}

/**
 * Checks two conditions which are neccesary for global infeasibility, and also
 * sufficient for global infeasibility when cᵢ is convex.
 *
 * @param TODO
 * @param gradientComplimentarity The gradient ∇cᵢᵀy. XXX: we currently only
 *   accept a dense expression, but if making dense copies becomes prohibitively
 *   expensive then we could take a EigenBase<Derived> and manually iterate to
 *   compute the L₁ norm.
 * @param TODO
 */
template <typename Derived>
inline bool IsInequalityLocallyInfeasible(
    const Eigen::VectorXd& y, const Eigen::VectorXd& s,
    const Eigen::VectorXd& c_i,
    const Eigen::EigenBase<Derived>& gradientComplimentarity,
    const double ε_far, const double ε_inf) {
  using Scalar = typename Eigen::EigenBase<Derived>::Scalar;
  Scalar gradientComplimentarityNorm = 0.0;
  for (const Scalar& x : gradientComplimentarity) {
    gradientComplimentarityNorm += std::abs(x);
  }
  // Claim: Let {(xₖ, sₖ, yₖ)}ₖ be a sequence of with limit (x*, s*, y*).
  // If (x*, s*, y*) is infeasible, then Γ_inf(xₖ, sₖ, yₖ) → 0.
  //
  // In the above sense, this condition is necessary for local infeasibility,
  // but it is not sufficient since there are cases where Γ_inf(x*, s*, y*) = 0
  // and (x*, s*, y*) is feasible and the limit of a sequence of iterates
  // generated by the one-phase algorithm.
  const double Γ_inf =
      (gradientComplimentarityNorm + s.transpose() * y) / y.lpNorm<1>();
  // The additional Γ_far and complimentarity conditions are in fact sufficient
  // (see Observation 1 in [4]) to show global infeasibility for a problem with
  // convex constraints; we hope that Γ_far also eliminates some spurious local
  // infeasibility results in the non-convex case.
  const double negatedComplimentarity = c_i.transpose() * y;
  const double Γ_far = gradientComplimentarityNorm / (negatedComplimentarity);

  return negatedComplimentarity > 0 && Γ_far <= ε_far && Γ_inf <= ε_inf;
}

/**
 * Checks a very simple unboundedness criterion.
 *
 * @param TODO
 */
inline bool IsUnbounded(const Eigen::VectorXd& x, const double ε_unbd) {
  // Justification for this is unclear.
  return 1.0 / x.lpNorm<Eigen::Infinity>() >= 1.0 / ε_unbd;
}
}  // namespace sleipnir
